{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.datasets import ImageFolder\nimport time\nimport copy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\ntrain_dir = '/kaggle/input/fer2013/train'\ntest_dir = '/kaggle/input/fer2013/test'\n\ntransform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrain_dataset = ImageFolder(root=train_dir, transform=transform)\ntest_dataset = ImageFolder(root=test_dir, transform=transform)\n\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\nclass_names = train_dataset.classes\nprint(\"Class names:\", class_names)\n\nmodel = models.resnet18(pretrained=True)\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, len(class_names))\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch}/{num_epochs - 1}')\n        print('-' * 10)\n\n        for phase in ['train', 'val']:\n            model.train() if phase == 'train' else model.eval()\n            running_loss, running_corrects = 0.0, 0\n            loader = train_loader if phase == 'train' else test_loader\n\n            for inputs, labels in loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                \n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                scheduler.step()\n\n            epoch_loss = running_loss / len(loader.dataset)\n            epoch_acc = running_corrects.double() / len(loader.dataset)\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    model.load_state_dict(best_model_wts)\n    return model\n\nmodel = train_model(model, criterion, optimizer, exp_lr_scheduler, num_epochs=25)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-09T17:27:59.886506Z","iopub.execute_input":"2024-11-09T17:27:59.886872Z","iopub.status.idle":"2024-11-09T18:03:00.349076Z","shell.execute_reply.started":"2024-11-09T17:27:59.886837Z","shell.execute_reply":"2024-11-09T18:03:00.347818Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda:0\nClass names: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 203MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0/24\n----------\ntrain Loss: 1.5651 Acc: 0.3960\nval Loss: 1.3677 Acc: 0.4753\n\nEpoch 1/24\n----------\ntrain Loss: 1.2898 Acc: 0.5037\nval Loss: 1.2478 Acc: 0.5195\n\nEpoch 2/24\n----------\ntrain Loss: 1.1882 Acc: 0.5480\nval Loss: 1.1901 Acc: 0.5522\n\nEpoch 3/24\n----------\ntrain Loss: 1.1141 Acc: 0.5771\nval Loss: 1.1647 Acc: 0.5599\n\nEpoch 4/24\n----------\ntrain Loss: 1.0562 Acc: 0.6014\nval Loss: 1.1573 Acc: 0.5680\n\nEpoch 5/24\n----------\ntrain Loss: 0.9995 Acc: 0.6223\nval Loss: 1.1121 Acc: 0.5889\n\nEpoch 6/24\n----------\ntrain Loss: 0.9505 Acc: 0.6434\nval Loss: 1.1275 Acc: 0.5868\n\nEpoch 7/24\n----------\ntrain Loss: 0.8681 Acc: 0.6751\nval Loss: 1.0997 Acc: 0.5942\n\nEpoch 8/24\n----------\ntrain Loss: 0.8401 Acc: 0.6873\nval Loss: 1.1089 Acc: 0.5995\n\nEpoch 9/24\n----------\ntrain Loss: 0.8225 Acc: 0.6939\nval Loss: 1.1082 Acc: 0.6016\n\nEpoch 10/24\n----------\ntrain Loss: 0.8140 Acc: 0.6981\nval Loss: 1.0966 Acc: 0.6080\n\nEpoch 11/24\n----------\ntrain Loss: 0.8025 Acc: 0.7006\nval Loss: 1.1121 Acc: 0.6082\n\nEpoch 12/24\n----------\ntrain Loss: 0.7960 Acc: 0.7037\nval Loss: 1.1098 Acc: 0.5978\n\nEpoch 13/24\n----------\ntrain Loss: 0.7865 Acc: 0.7059\nval Loss: 1.1030 Acc: 0.6089\n\nEpoch 14/24\n----------\ntrain Loss: 0.7741 Acc: 0.7136\nval Loss: 1.0918 Acc: 0.6091\n\nEpoch 15/24\n----------\ntrain Loss: 0.7700 Acc: 0.7149\nval Loss: 1.0978 Acc: 0.6049\n\nEpoch 16/24\n----------\ntrain Loss: 0.7718 Acc: 0.7120\nval Loss: 1.0997 Acc: 0.6064\n\nEpoch 17/24\n----------\ntrain Loss: 0.7716 Acc: 0.7132\nval Loss: 1.1128 Acc: 0.5988\n\nEpoch 18/24\n----------\ntrain Loss: 0.7738 Acc: 0.7127\nval Loss: 1.0977 Acc: 0.6098\n\nEpoch 19/24\n----------\ntrain Loss: 0.7640 Acc: 0.7180\nval Loss: 1.1148 Acc: 0.6024\n\nEpoch 20/24\n----------\ntrain Loss: 0.7639 Acc: 0.7174\nval Loss: 1.1140 Acc: 0.6064\n\nEpoch 21/24\n----------\ntrain Loss: 0.7656 Acc: 0.7176\nval Loss: 1.1029 Acc: 0.5996\n\nEpoch 22/24\n----------\ntrain Loss: 0.7638 Acc: 0.7190\nval Loss: 1.1056 Acc: 0.5995\n\nEpoch 23/24\n----------\ntrain Loss: 0.7598 Acc: 0.7189\nval Loss: 1.1111 Acc: 0.5991\n\nEpoch 24/24\n----------\ntrain Loss: 0.7583 Acc: 0.7180\nval Loss: 1.1127 Acc: 0.6032\n\nTraining complete in 34m 33s\nBest val Acc: 0.609780\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 132\u001b[0m\n\u001b[1;32m    130\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m    131\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_grid\u001b[49m(inputs)\n\u001b[1;32m    134\u001b[0m imshow(out, title\u001b[38;5;241m=\u001b[39m[class_names[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mcpu()])\n","\u001b[0;31mAttributeError\u001b[0m: module 'torch.utils' has no attribute 'make_grid'"],"ename":"AttributeError","evalue":"module 'torch.utils' has no attribute 'make_grid'","output_type":"error"}],"execution_count":2}]}